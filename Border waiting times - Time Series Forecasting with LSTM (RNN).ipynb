{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load general csv file\n",
    "#df = pandas.read_csv(\"reports_data.csv\") \n",
    "df = pandas.read_csv(\"garitas_data_newest.csv\")\n",
    "\n",
    "#drop out id column\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "# Read garita\n",
    "df_Ysidro = df[df[\"port\"] == \"San Ysidro\"] \n",
    "df_Ysidro.loc[:,'time'] = pandas.to_datetime(df_Ysidro.loc[:,'time']) #check to_datetime\n",
    "\n",
    "# Mark b'' values with 0\n",
    "type_line = ['vehicle_ready', 'vehicle_sentry', 'vehicle_standard', 'pedestrian_ready', 'pedestrian_standard']\n",
    "for line in type_line:\n",
    "    #df_calexico[line] = df_calexico[line].replace([\"b''\"], '0')\n",
    "    df_Ysidro[line] = df_Ysidro[line].replace([\"\"], '0')\n",
    "\n",
    "#Fill NA/NaN values\n",
    "X = df_Ysidro.fillna(-1)[[\"vehicle_ready\", \"time\"]] #X:pandas.core.frame.Dataframe\n",
    "\n",
    "#Create new column: time_before\n",
    "data = X[\"vehicle_ready\"] #id and wait-time\n",
    "\n",
    "# add previous_time column\n",
    "time_before = [data.iloc[1]] #locks first time\n",
    "for i in range(1, len(data) - 1):\n",
    "    #time_before.append(data.iloc[i + 1]) \n",
    "    time_before.append(data.iloc[i - 1]) #new df column with previous time\n",
    "time_before.append(0) #0 value to last space of time_before array\n",
    "\n",
    "#Rename vehicle_ready column\n",
    "X.rename(columns={'vehicle_ready': 'actual_time'}, inplace=True)\n",
    "#Specify new columns with separated values\n",
    "X[\"previous_time\"] = time_before   #TODO: CHECK THIS COLUMN\n",
    "X[\"weekday\"] = X[\"time\"].apply(lambda x: x.weekday()) # 0 Monday , 6 Sunday\n",
    "X[\"hour\"] = X[\"time\"].apply(lambda x: x.hour)\n",
    "X[\"minute\"] = X[\"time\"].apply(lambda x: x.minute)\n",
    "X[\"second\"] = X[\"time\"].apply(lambda x: x.second)\n",
    "X['day'] =  X[\"time\"].apply(lambda x: x.day)\n",
    "X['month'] =  X[\"time\"].apply(lambda x: x.month)\n",
    "X['year'] =  X[\"time\"].apply(lambda x: x.year)\n",
    "\n",
    "#drop out time (utc format column)\n",
    "X.drop(\"time\", axis=1, inplace=True) \n",
    "\n",
    "X.index.name = 'index'\n",
    "\n",
    "# summarize first 5 rows\n",
    "#X.head()\n",
    "\n",
    "# save to file\n",
    "#X.to_csv('San_Ysidro_vehicle_ready.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot wait-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#df = pandas.read_csv('garita_San Ysidro.csv', header=0, index_col=0)\n",
    "df = X\n",
    "#convert each row into a numpy array \n",
    "values = df.values \n",
    "# specify columns to plot\n",
    "groups = [0]  \n",
    "i = 1\n",
    "# plot each column\n",
    "fig = pyplot.figure(figsize=(10, 6), dpi=500) #set figure size\n",
    "\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i) #made subplot; might want to plot other columns later\n",
    "    \n",
    "    pyplot.plot(values[:500, group]) #plot all waiting times\n",
    "    \n",
    "    #pyplot.title(df.columns[group], x=0.2, y=0.8, loc='left')\n",
    "    pyplot.ylabel('Tiempo espera (min)')\n",
    "    pyplot.xlabel('Muestra')\n",
    "    pyplot.title('Garita San Ysidro', x=0.7, y=0.8, loc='left')\n",
    "    i += 1\n",
    "pyplot.show()\n",
    "#np.amax(values[:,0]) data has anormal max of 458 min = 7 hr\n",
    "\n",
    "#Save image file\n",
    "#fig.savefig('San_Ysidro_Vehicle_Ready.pdf', format='pdf', dpi=2000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]   #shape: returns the dimensions of the array\n",
    "    #data.shape[1]:  no. of columns of array\n",
    "    df = pandas.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ..., t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pandas.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('San_Ysidro_vehicle_ready.csv', header=0, index_col=0)\n",
    "values = dataset.values #convert each row into a numpy array \n",
    "\n",
    "# integer encode direction  (OUR DATA DOES NOT NEED ENCODING)\n",
    "#encoder = LabelEncoder()\n",
    "#values[:,4] = encoder.fit_transform(values[:,4])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) #FR Desired range of transformed data: min=0,max=1\n",
    "scaled = scaler.fit_transform(values) #Tranfsorm: Scaling features of 'values' according to feature_range\n",
    "\n",
    "# frame as supervised learning\n",
    "# specify the number of lag hours\n",
    "#NOTE: He has time steps of 1 hour, we have smaller time steps \n",
    "#n_hours = 5 #Supose take last 5 hours (Note: it is not actually last five hours, measure intervals tend to vary)\n",
    "n_hours = 300 \n",
    "n_features = 9 #Have 9 raw features\n",
    "reframed = series_to_supervised(scaled, n_hours, 1) #Look at the past with lag observations n_hours\n",
    "#Input params make it multi-step forecasting, e.g., (scaled,2,2)\n",
    "\n",
    "# drop columns (Only want to predict actual_waiting_time: var1(t))\n",
    "#reframed.drop([('var%d(t)' % (j+1)) for j in range(1, n_features)], axis=1, inplace=True) #Last column is var1(t)\n",
    "#var1 : Is the actual_waiting_time ---> variable-to-predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit an LSTM on the multivariate input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into train and test sets\n",
    "values = reframed.values\n",
    "#n_train_hours = 30 * 24 # 1 months: time lapse of training set (complete 31.7.17 to 12.10.17)\n",
    "train = values[0:n_hours, :] #Take first n_hours to train (THIS CAN CHANGE IF COLLECT MORE DATA) (array of arrays)\n",
    "test = values[n_hours:, :] #Rest of time \n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features  #All previous obs to predict actual t\n",
    "train_X, train_y = train[:, 0:n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "#train_X: Take n_hours*n_features columns as INPUT for the obs of all features across the previous n_hours (n_obs)\n",
    "#train_y: take just the wait_time variable as output (var1(t))\n",
    "\n",
    "# LSTM input params: reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#5 Step Life-Cycle for Long Short-Term Memory Models in Keras\n",
    "\n",
    "# 1 DESIGN NETWORK\n",
    "model = Sequential() #container of neural network layers Sequential class\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]))) #The input to every LSTM layer must be three-dimensional!\n",
    "#50 neurons hidden layers, timesteps, features\n",
    "\n",
    "model.add(Dense(1)) # 1 neuron in the fully connected output layer with a linear (default) activation function\n",
    "\n",
    "# 2 COMPILE NETWORK (CHECK: LOSS AND OPTIMIZER OF A MODEL)\n",
    "#model.compile(loss='mae', optimizer='adam')    \n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "#ADAM optimization algorithm: for first-order gradient-based optimization of stochastic objective functions\n",
    "#Mean Absolute Error: loss function\n",
    "#The lower the Loss, the better a model \n",
    "\n",
    "#Question: Why do we get loss for train and validation (test) ???\n",
    "\n",
    "# 3 FIT NETWORK (adapt the weights of training dataset)\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size= len(train_X), validation_data=(test_X, test_y), verbose=2, shuffle=False) \n",
    "\n",
    "#history object provides a summary of the performance of the model during training\n",
    "#Epoch: A full pass over all of your training data. \n",
    "\n",
    "# plot history\n",
    "fig = pyplot.figure(figsize=(5, 3), dpi=800) #set figure size\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.ylabel('Pérdida')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "#fig.savefig('San_Ysidro_300_hour_50_epochs.png', format='png', dpi=900, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4 EVALUATE NETWORK\n",
    "#Returns the loss value & metrics values for the model in test mode.\n",
    "loss = model.evaluate(train_X, train_y, verbose=0)\n",
    "print(loss)\n",
    "\n",
    "# 5. make predictions\n",
    "#predictions = model.predict(X, verbose=0)\n",
    "#print(predictions[:, 0])\n",
    "\n",
    "# 5 MAKE PREDICTIONS\n",
    "yhat = model.predict(test_X) #yhat predicted value (done on the test set) . yhat compares with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features)) #Check this reshaping\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -8:]), axis=1) #Ours is 8 (got 9 features)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -8:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "#Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 490\n",
    "fig = pyplot.figure(figsize=(10, 6), dpi=500) #set figure size\n",
    "pyplot.plot(range(points), inv_y[0:points], label='Test')\n",
    "pyplot.plot(range(points), inv_yhat[0:points], label='Prediction')\n",
    "#pyplot.plot(range(0,points), test_y[0:points], '-go')\n",
    "#pyplot.plot(range(0,points), yhat[0:points], '-bo')\n",
    "pyplot.ylabel('Wait time (min)')\n",
    "pyplot.xlabel('Sample')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "#fig.savefig('San_Ysidro_prediction_300_hour_50_epochs.png', format='png', dpi=650, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
